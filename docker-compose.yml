name: smartETL

services:
  postgres:
    image: postgres:17.2
    container_name: dor_postgres
    env_file:
      - .env
    volumes:
      - postgres-data:/var/lib/postgresql/data
      - ./postgresql/init.sql:/docker-entrypoint-initdb.d/init.sql
    ports:
      - "5432:5432"
    restart: always
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "admin", "-d", "postgres"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      dor_network:
        aliases:
          - dor_network

  pgadmin:
    image: dpage/pgadmin4:8.14.0
    container_name: dor_pgadmin
    env_file:
      - .env
    ports:
      - "5050:80"
    depends_on:
      postgres:
          condition: service_healthy
    volumes:
      - ./conf/postgresql/servers.json:/pgadmin4/servers.json
    networks:
      dor_network:
        aliases:
          - dor_network

  python_app:
    container_name: dor_scripts
    build:
      context: .
      dockerfile: pythonApp.Dockerfile
    env_file:
      - .env
    depends_on:
      postgres:
          condition: service_healthy
    volumes:
      - ./data:/data
    entrypoint: ["python", "smartETL.py"]
    networks:
      dor_network:
        aliases:
          - dor_network

  # Kafka Zookeeper
  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    container_name: my_zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
    networks:
      dor_network:
        aliases:
          - dor_network

  kafka-manager:
    image: hlebalbau/kafka-manager:3.0.0.5
    container_name: kafka-manager
    ports:
      - "9000:9000"
    environment:
      ZK_HOSTS: "zookeeper:2181"
      APPLICATION_SECRET: "randomsecret"
    depends_on:
      - zookeeper
      - kafka
    networks:
      dor_network:
        aliases:
          - dor_network

  # Kafka Broker
  kafka:
    image: confluentinc/cp-kafka:latest
    container_name: my_kafka
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_MESSAGE_MAX_BYTES: 209715200
      KAFKA_REPLICA_FETCH_MAX_BYTES: 209715200
      KAFKA_FETCH_MESSAGE_MAX_BYTES: 209715200
    ports:
      - "9092:9092"
    depends_on:
      - zookeeper
    networks:
      dor_network:
        aliases:
          - dor_network
    healthcheck:
      test: ["CMD", "kafka-topics", "--bootstrap-server", "localhost:9092", "--list"]
      interval: 10s
      timeout: 5s
      retries: 5


  # Python Producer
  producer:
    build:
      dockerfile: kafka.Dockerfile
      context: .
    container_name: my_python_producer
    depends_on:
      kafka:
        condition: service_healthy
      postgres:
        condition: service_healthy
    env_file:
      - .env
    volumes:
      - ./data:/data
    entrypoint: ["python", "producer.py"]
    networks:
      dor_network:
        aliases:
          - dor_network


  # Python Consumer (for consuming Kafka messages and inserting into PostgreSQL)
  consumer:
    build:
      dockerfile: kafka.Dockerfile
      context: .
    container_name: my_python_consumer
    depends_on:
      - kafka
      - postgres
    entrypoint: ["python", "consumer.py"]
    env_file:
      - .env
    networks:
      dor_network:
        aliases:
          - dor_network

  grafana:
    image: grafana/grafana:11.5.1
    container_name: dor_grafana
    ports:
      - "3000:3000"
    env_file:
      - .env
    volumes:
      - grafana-data:/var/lib/grafana
      - ./conf/grafana/provisioning:/etc/grafana/provisioning
      - ./conf/grafana/dashboards:/import
    depends_on:
      postgres:
          condition: service_healthy
    networks:
      dor_network:
        aliases:
          - dor_network

  airflow:
    build:
      context: .
      dockerfile: dockerfile_airflow/dockerfile
    container_name: dor_airflow
    env_file:
      - .env
    depends_on:
      postgres:
        condition: service_healthy
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${POSTGRES_HOST}:${POSTGRES_PORT}/airflow
      - AIRFLOW__CORE__FERNET_KEY=${AIRFLOW_FERNET_KEY}
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
    volumes:
        - ./airflow/dags:/opt/airflow/dags
        - logs_data:/opt/airflow/logs
        - ./airflow/plugins:/opt/airflow/plugins
    ports:
      - "8080:8080"
    networks:
      dor_network:
        aliases:
          - dor_network

volumes:
  postgres-data:
  grafana-data:
  logs_data:

networks:
  dor_network:
