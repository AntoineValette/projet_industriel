# Projet nÂ°7 : smartETL "DOR"

## ğŸ’¡ Description

- Projet industriel Smart ETL qui a pour objectif de valoriser les logs des ETLs pour l'Ã©quipe Data de Primever. 
---

## âš ï¸ PrÃ©-requis 

- conda
- docker 
- git
- linux / unix / macos 
- python 3.12
- postgresql 17.2

---
```
git clone git@gitlab-student.centralesupelec.fr:PI7/smartETL.git
```

DÃ©placer les fichiers logs dans le rÃ©pertoire ./data du repertoire clonÃ©

------
## ğŸ‘©â€ğŸ’» Developpement

```
conda create -n smartETL-dev
conda activate smartETL-dev
conda install python=3.12.8
conda install sqlalchemy pandas psycopg2 fastparquet
conda install jupyterlab matplotlib seaborn scikit-learn numpy  plotly lxml   pyarrow apache-airflow confluent-kafka    
```
RegÃ©nÃ©rer le fichier requirements-dev.txt
```
pip list --format=freeze > requirements.txt 
```
---
## ğŸš€ Run

Pour lancer l'application : 
```
# construit les images docker 
docker compose build 

# lance le docker compose 
docker compoose up -d

# supprime le docker compose mais garde le volume 
docker compose down 

# supprime le docker compose avec les volumes 
docker compose down -v 
```

NB: pour gÃ©nÃ©rer le fichier conda pour la prod : 
```
git clone git@gitlab-student.centralesupelec.fr:PI7/smartETL.git
cd smartETL
conda create -n smartETL
conda activate smartETL
conda install python=3.12.8
conda install sqlalchemy pandas psycopg2  fastparquet

pip list --format=freeze > requirements.txt 
```
---
## ğŸŒ³ Arborescence du projet

L'arborescence ci-dessous prÃ©sente la structure complÃ¨te du projet. Chaque section est commentÃ©e pour indiquer son rÃ´le ou son contenu principal.
```
smartETL
â”œâ”€â”€ conf
â”‚    â”œâ”€â”€ airflow                         # fichiers de config pour airflow (il existe un volume pour les plugins). Les jobs sont dÃ©finis dans ./python/dags/
â”‚    â”‚    â””â”€â”€ plugins     
â”‚    â”œâ”€â”€ grafana                         # fichiers de config pour Grafane
â”‚    â”‚    â”œâ”€â”€ dashboards                  # ensemble des moidÃ¨les des dashboards - Ã  modifier directement dans Grafana, mais Ã  sauvegarder ici pour Ã©viter une suppression accidentelle avec un docker compose down -v 
â”‚    â”‚    â””â”€â”€ provisioning                # config de la source de donnÃ©es (connexion Ã  Postgres automatique avec ID commun) + un exemple d'un fichier d'alerting + un fichier de config dashboard annexe
â”‚    â””â”€â”€ postgresql                      # paramÃ¨trage de Postgres - modifier user et mdp
â”œâ”€â”€ data                                # ensemble des fichiers .csv et .parquet qui sont utilisÃ©es par l'appli : Ã  priori les paths seront Ã  modifier pour correspondre Ã  l'arborescence de la VM
â”‚    â”œâ”€â”€ ...
â”œâ”€â”€ doc                                 # des schÃ©mas et une arborescence dÃ©taillÃ©e
â”‚    â”œâ”€â”€ ...
â”œâ”€â”€ docker                              # ensemble des dockerfiles, requirements et entrypoints (si besoin) pour les images qui sont personnalisÃ©es
â”‚    â”œâ”€â”€ airflow
â”‚    â”œâ”€â”€ kafka
â”‚    â””â”€â”€ python
â”œâ”€â”€ notebook                            # un historique des notebooks utilisÃ©es pendant les premiÃ¨res phases du projet. Pas nÃ©cessaire au bon fonctionnement de l'appli, mais utile pour les curieux.
â”‚    â””â”€â”€ ...
â”œâ”€â”€ postgresql                          # Fichier de configuration des tables de Postgres. 
â””â”€â”€ python                              # ensemble des scripts (scripts d'initilisation et jobs orchestrÃ©s par Airflow)
    â”œâ”€â”€ ETL                             # ensemble des scripts de chargement des logs Ã  l'initialisation
    â”‚    â””â”€â”€ ...
    â”œâ”€â”€ core                            # fonctions et mÃ©thodes communes (notamment un script de classification des erreurs)
    â”‚    â””â”€â”€ ...
    â”œâ”€â”€ dags                            # configuation des jobs (un job test et ub job fusion) orchestrÃ© par Airflow + des fonctions de transformations de datafraame
    â”‚    â””â”€â”€ ...
    â”œâ”€â”€ init                            # init standard
    â”œâ”€â”€ kfk                             # scripts pour le streaming avec Kafka
    â”‚    â”œâ”€â”€ consumer
    â”‚    â””â”€â”€ producer
    â””â”€â”€ waiting                         # fonctions de synchronisation (pemet d'attendre la fin du lancement/execution de certains services/scripts qui n'est pas possible avec la parmÃ¨trage isHealthy de Docker Compose)
    â””â”€â”€ consumer.py                     # produit (envoie) des messages vers un ou plusieurs topics Kafka
    â””â”€â”€ producer.py                     # sâ€™abonne Ã  un ou plusieurs topics, et lit en continu les messages qui y sont publiÃ©s

```

---
## ğŸ““ Notebooks
Historiquement, on a commencÃ© l'analyse des diffÃ©rents fichiers .csv de logs avec des notebooks jupyter. Ces notebooks sont plutÃ´t bien commentÃ©.
Pour les curieux, le notebook ./notebook/fusion/fusion_log-logerreur.ipynb est trÃ¨s similaire Ã  ./python/dags/fusion_dag.py. Le notebook est Ã  l'origine de l'aggregation des sources pour crÃ©er la VO de dataset. NB : la table dataset finale dans Postgres est lÃ©gÃ¨rement diffÃ©rente au finale. 

---
## ğŸ’¡ Tips & Tricks 

### Grafana 
Pour Ã©diter les dashboards, le plus simple est de le faire directement dans Grafana. En les enregistrant via l'interface de Grafana, les dashboards modifiÃ©s seront enregistrÃ©s dans un volume.

âš ï¸ ATTENTION : avec une suppression des volumes (docker compose down -v), les modifications de dashboards existants et la crÃ©ation de nouveaux dashboards seraient perdues. 

âš ï¸ Il est donc fortement, fortement conseillÃ© d'enregister les dashboards ET de les ***exporter en JSON*** Ã  nouveau dans ./conf/grafana/dahboards. 

### Airflow
Le paramÃ¨trage des jobs d'Airflow est situÃ© dans :
- ./python/dags/test_dag.py : un dag de test pour tester le conteneur et le fonctionement d'Airflow. Ce job n'a pas d'autre utilitÃ©
- ./python/dags/fusion_dag.py : le dag qui met Ã  jour la table dataset dans Postgres toutes les heures avec les donnÃ©es intÃ©grÃ©es par Kafka

Les autres jobs peuvent Ãªtres crÃ©Ã©s ici. 
