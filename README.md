# Projet n¬∞7 : smartETL "DOR"

## üí° Description

- Projet industriel Smart ETL qui a pour objectif de valoriser les logs des ETLs pour l'√©quipe Data de Primever. 
---

## ‚ö†Ô∏è Pr√©-requis 

- conda
- docker 
- git
- linux / unix / macos 
- python 3.12
- postgresql 17.2

---
```
git clone git@gitlab-student.centralesupelec.fr:PI7/smartETL.git
```

D√©placer les fichiers logs dans le r√©pertoire ./data du repertoire clon√©

------
## üë©‚Äçüíª Developpement

```
conda create -n smartETL-dev
conda activate smartETL-dev
conda install python=3.12.8
conda install sqlalchemy pandas psycopg2 fastparquet
conda install jupyterlab matplotlib seaborn scikit-learn numpy  plotly lxml   pyarrow apache-airflow confluent-kafka    
```
Reg√©n√©rer le fichier requirements-dev.txt
```
pip list --format=freeze > requirements.txt 
```
---
## üöÄ Run

Pour lancer l'application : 
```
# construit les images docker 
docker compose build 

# lance le docker compose 
docker compoose up -d

# supprime le docker compose mais garde le volume 
docker compose down 

# supprime le docker compose avec les volumes 
docker compose down -v 
```

NB: pour g√©n√©rer le fichier conda pour la prod : 
```
git clone git@gitlab-student.centralesupelec.fr:PI7/smartETL.git
cd smartETL
conda create -n smartETL
conda activate smartETL
conda install python=3.12.8
conda install sqlalchemy pandas psycopg2  fastparquet

pip list --format=freeze > requirements.txt 
```
---
## Config
### Grafana 
C'est ici que sont stock√©s les mod√®les des diff√©rents dashboards, la connexion √† la base Postgres et un exemple d'alerte. Le plus simple pour √©diter ces fichiers est de la faire directement dans Grafana et les exporter √† nouveau pour enregistrer les modificiations.

### Airflow
Fichiers de config d'airflow, transparents pour l'utilisateur. Le param√®trage des jobs d'Airflow est situ√© dans :
- ./python/dags/test_dag.py (un dag de test pour tester le conteneur)
- ./python/dags/fusion_dag.py (le dag qui met √† jour la table dataset dans Postgres toutes les heures avec les donn√©es int√©gr√©es par Kafka)

### Postgres
Fichier de configuration de Postgres. 

---
## Notebook
Historiquement, on a commenc√© l'analyse 